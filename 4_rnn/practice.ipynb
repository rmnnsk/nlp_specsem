{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Практическая чаcть\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy \n",
    "from collections import defaultdict\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Загрузка датасета."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Cоставьте таблицу, в которой указано число токенов, уникальных токенов, предложений для каждой из трех частей датасета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = './filimdb_evaluation/PTB/'\n",
    "filenames = ['train', 'valid', 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>token_cnt</th>\n",
       "      <th>unique_tokens</th>\n",
       "      <th>sentences_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>887521</td>\n",
       "      <td>9999</td>\n",
       "      <td>42068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>valid</td>\n",
       "      <td>70390</td>\n",
       "      <td>6021</td>\n",
       "      <td>3370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>78669</td>\n",
       "      <td>6048</td>\n",
       "      <td>3761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    file  token_cnt  unique_tokens  sentences_cnt\n",
       "0  train     887521           9999          42068\n",
       "1  valid      70390           6021           3370\n",
       "2   test      78669           6048           3761"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_file_info(filename):\n",
    "    global folder_name \n",
    "    tokens_cnt = defaultdict(int)\n",
    "    cnt_lines = 0\n",
    "    with open(folder_name + f\"ptb.{filename}.txt\", 'r') as inp:\n",
    "        for line in inp:\n",
    "            cnt_lines += 1\n",
    "            for token in line.strip().split():\n",
    "                tokens_cnt[token] += 1\n",
    "    total_tokens = sum(tokens_cnt.values())\n",
    "    unique_tokens = len(tokens_cnt.keys())\n",
    "    return filename, total_tokens, unique_tokens, cnt_lines\n",
    "\n",
    "data = {\n",
    "    'file':[],\n",
    "    'token_cnt':[],\n",
    "    'unique_tokens':[],\n",
    "    'sentences_cnt': []\n",
    "}\n",
    "\n",
    "for f in filenames:\n",
    "    f_data = get_file_info(f)\n",
    "    data['file'].append(f_data[0])\n",
    "    data['token_cnt'].append(f_data[1])\n",
    "    data['unique_tokens'].append(f_data[2])\n",
    "    data['sentences_cnt'].append(f_data[3])\n",
    "    \n",
    "df = pd.DataFrame(data=data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Приведите 10 самых частотных и 10 самых редких токенов с их частотами.\n",
    "(тут видимо для всех файлов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_cnt = defaultdict(int)\n",
    "for f in filenames:\n",
    "     with open(folder_name + f\"ptb.{f}.txt\", 'r') as inp:\n",
    "        for line in inp:\n",
    "            for token in line.strip().split():\n",
    "                tokens_cnt[token] += 1\n",
    "cnt_list = list(tokens_cnt.items())\n",
    "cnt_list.sort(key=lambda x: x[1])\n",
    "most_frequent_data = {'word':[], 'cnt':[]}\n",
    "for w, c in cnt_list[-10:][::-1]:\n",
    "    most_frequent_data['word'].append(w)\n",
    "    most_frequent_data['cnt'].append(c)\n",
    "least_frequent_data = {'word':[], 'cnt':[]}\n",
    "for w, c in cnt_list[:10]:\n",
    "    least_frequent_data['word'].append(w)\n",
    "    least_frequent_data['cnt'].append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>59421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>53299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N</td>\n",
       "      <td>37607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of</td>\n",
       "      <td>28427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to</td>\n",
       "      <td>27430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a</td>\n",
       "      <td>24755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>in</td>\n",
       "      <td>21032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>and</td>\n",
       "      <td>20404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>'s</td>\n",
       "      <td>11555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>for</td>\n",
       "      <td>10436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word    cnt\n",
       "0    the  59421\n",
       "1  <unk>  53299\n",
       "2      N  37607\n",
       "3     of  28427\n",
       "4     to  27430\n",
       "5      a  24755\n",
       "6     in  21032\n",
       "7    and  20404\n",
       "8     's  11555\n",
       "9    for  10436"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data=most_frequent_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>buffet</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lancaster</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>barnett</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rewrite</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>downgrading</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>backgrounds</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>stanza</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vessel</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>unstable</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>peat</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word  cnt\n",
       "0       buffet    5\n",
       "1    lancaster    5\n",
       "2      barnett    5\n",
       "3      rewrite    5\n",
       "4  downgrading    5\n",
       "5  backgrounds    5\n",
       "6       stanza    5\n",
       "7       vessel    5\n",
       "8     unstable    5\n",
       "9         peat    5"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data=least_frequent_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Какие специальные токены уже есть в выборке, что они означают?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вроде как, токены выглядят как текст в треугольных кавычках. Поищем такие фрагменты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<unk>'}\n"
     ]
    }
   ],
   "source": [
    "spec_tokens = set()\n",
    "for f in filenames:\n",
    "     with open(folder_name + f\"ptb.{f}.txt\", 'r') as inp:\n",
    "        for line in inp:\n",
    "            cur_spec = set(re.findall(r'<[a-z]*>', line))\n",
    "            spec_tokens = spec_tokens.union(cur_spec)\n",
    "print(spec_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получается, что либо я перепутал тип токенов, либо у нас есть только один специальный токен : $<unk>$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прочитав документацию по датасету, можно понять, что в нём содержатся 10000 самых популярных токенов, а все остальные токены заменяются на $<unk>$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Генерацей батчей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_batch(ind, X_b, Y_b):\n",
    "    print(f\"Batch # {ind}\")\n",
    "    for i in range(len(X_b)):\n",
    "            print(X_b[i], ' ', Y_b[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch # 0\n",
      "['мороз', 'и', 'солнце']   ['и', 'солнце', 'день']\n",
      "['ты', 'дремлешь', 'друг']   ['дремлешь', 'друг', 'прелестный']\n",
      "Batch # 1\n",
      "['день', 'чудесный', 'еще']   ['чудесный', 'еще', 'ты']\n",
      "['прелестный', 'пора', 'красавица']   ['пора', 'красавица', 'проснись']\n"
     ]
    }
   ],
   "source": [
    "def batch_generator(data_path, batch_size, num_steps, debug=False):\n",
    "    eos_token = '<eos>'\n",
    "    L_tokens = []\n",
    "    with open(data_path, 'r', encoding='utf-8') as inp:\n",
    "        for line in inp:\n",
    "            line_tokens = list(map(str.lower, line.strip().split()))\n",
    "            L_tokens.extend(line_tokens)\n",
    "    L_shifted = L_tokens[1:] + [eos_token]    \n",
    "    \n",
    "    unk_len = len(L_tokens) // batch_size\n",
    "    X_lists = [L_tokens[i : i + unk_len] for i in range(0, len(L_tokens), unk_len) if len(L_tokens[i : i + unk_len]) == unk_len]\n",
    "    Y_lists = [L_shifted[i : i + unk_len] for i in range(0, len(L_shifted), unk_len)  if len(L_shifted[i : i + unk_len]) == unk_len] \n",
    "       \n",
    "    for i in range(0, unk_len, num_steps):\n",
    "        \n",
    "        X_batch = []\n",
    "        Y_batch = []\n",
    "        for lst in X_lists:\n",
    "            X_batch.append(lst[i : i + num_steps])\n",
    "        for lst in Y_lists:\n",
    "            Y_batch.append(lst[i : i + num_steps])\n",
    "        if debug:\n",
    "            print_batch(i // num_steps, X_batch, Y_batch)\n",
    "    \n",
    "batch_generator(folder_name + \"small.txt\", batch_size = 2, num_steps = 3, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На файле из первых трех строчек **train** датасета функция создаёт батчи похожие на правду."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Реализация LSTM LM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Класс LSTMCell\n",
    "Для реализации LSTM ячейки будем отталкиваться от реализации обычной RNN ячейки из семинара."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCell(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        '''\n",
    "        Args:\n",
    "            input_size: Size of token embedding\n",
    "            hidden_size: Size of hidden state of LSTM cell\n",
    "        '''\n",
    "        super(RNNCell, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # Creating matrices whose weights will be trained\n",
    "        # Token embedding (input of this cell) will be multiplied by this matrix\n",
    "        self.U_input = nn.Parameter(torch.Tensor(input_size, 4 * hidden_size))\n",
    "        self.BU_input = nn.Parameter(torch.Tensor(4 * hidden_size))\n",
    "\n",
    "        # Creating matrices whose weights will be trained\n",
    "        # Hidden state from previous step will be multipied by this matrix\n",
    "        # Zero hidden state at the initial step\n",
    "        self.W_hidden = nn.Parameter(torch.Tensor(hidden_size, 4 * hidden_size))\n",
    "        self.BW_hidden = nn.Parameter(torch.Tensor(4 * hidden_size))\n",
    "\n",
    "        # Weights initialization\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def forward(self, inp: torch.Tensor, cell_state: torch.Tensor, hidden_state: torch.Tensor) -> (torch.Tensor, torch.Tensor):\n",
    "        '''\n",
    "        Performes forward pass of the recurrent cell\n",
    "        Args:\n",
    "            inp: Output from Embedding layer at the current timestep\n",
    "                Tensor shape is (batch_size, emb_size)\n",
    "            cell_state: Output cell_state from previous recurrent step or zero state\n",
    "                Tensor shape is (batch_size, hidden_size)\n",
    "            hidden_state: Output hidden_state from previous recurrent step or zero state\n",
    "                Tensor shape is (batch_size, hidden_size)\n",
    "        Returns:\n",
    "            Output from LSTM cell\n",
    "        '''\n",
    "        hidden_mult = hidden_state @ W_hidden + BW_hidden\n",
    "        input_mult  = inp @ U_input + BU_input \n",
    "        matr_sum = input_mult + hidden_mult\n",
    "        \n",
    "        sum_chunk = matr_sum.chunk(chunks=4, dim=1)\n",
    "        f, i, o = torch.sigmoid(sum_chunk[0]), torch.sigmoid(sum_chunk[1]), torch.sigmoid(sum_chunk[2])\n",
    "        c_new = torch.tanh(sum_chunk[3])\n",
    "        \n",
    "        cell_state_new = cell_state * f + i * c_new\n",
    "        hidden_state_new = o * torch.tanh(cell_state_new)\n",
    "        \n",
    "        return cell_state_new, hidden_state_new\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        '''\n",
    "        Weights initialization\n",
    "        '''\n",
    "        stdv = 1.0 / np.sqrt(self.hidden_size)\n",
    "        for weight in self.parameters():\n",
    "            nn.init.uniform_(weight, -stdv, stdv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8 матриц и векторов смещений заменили на 2 каждого вида.<br>\n",
    "Всё перемножили и сложили по формулам, применили функции активация к каждой из 4 частей большой матрицы. <br>\n",
    "Дальше осталось просто всё правильно поэлементно перемножить и получить новые состояния ячейки и скрытое состояние."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Класс LSTMLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMLayer(torch.nn.Module):\n",
    "    def __init__(self, emb_size, hidden_size):\n",
    "        self.input_size = emb_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.LSTMCell = LSTMCell(emb_size, hidden_size)\n",
    "        \n",
    "    def forward(self, X_batch, initial_states=None):\n",
    "        if initial_states is None:\n",
    "            cell_state = np.zeros((X_batch.shape[0], self.hidden_size))\n",
    "            hidden_state = np.zeros((X_batch.shape[0], self.hidden_size))\n",
    "        else:\n",
    "            cell_state, hidden_state = initial_states\n",
    "            \n",
    "        #X_batch.shape = (num_steps, batch_size, emb_size)\n",
    "        #Need to transform this somewhere else in LSTM class\n",
    "        outputs = []\n",
    "        for timestamp in range(X_batch.shape[0]):\n",
    "            cell_state, hidden_state = self.LSTMCell(X_batch[timestamp], cell_state, hidden_state)\n",
    "            outputs.append(hidden_state)\n",
    "            \n",
    "        return torch.stack(outputs), (cell_state, hidden_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
